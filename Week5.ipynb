{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1M1OoIfuMpZ24bKdwD6Vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NandaAbhilash/CN6005/blob/main/Week5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_JqG6lPJ9k-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klbsTJ5r94Fk",
        "outputId": "8ed3ccf8-05c1-4daf-fc66-e4ca1b521756"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize and convert to float32\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "id": "ezXNSkbd96ao"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 has 3 color channels, so no need for np.expand_dims\n",
        "# The shapes are (50000, 32, 32, 3) for X_train and (10000, 32, 32, 3) for X_test\n",
        "\n",
        "# Convert labels to one-hot encoding (required for standard classification loss)\n",
        "# Note: The provided MNIST code used sparse_categorical_crossentropy which doesn't need this,\n",
        "# but for a comprehensive solution and better compatibility with potential model architectures, one-hot is often preferred.\n",
        "# For simplicity and consistency with the provided MNIST code's model.compile (which used 'sparse_categorical_crossentropy'),\n",
        "# we'll keep y_train and y_test as they are, but if the loss function changes, one-hot encoding would be needed.\n",
        "# For now, we proceed assuming 'sparse_categorical_crossentropy'.\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdMIYzT399G2",
        "outputId": "b9f41c1b-623d-430c-a29d-d0513882a3e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (50000, 32, 32, 3), y_train shape: (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_without_pooling():\n",
        "    inputs = layers.Input(shape=(32, 32, 3)) # Input is 32x32x3 (color image)\n",
        "\n",
        "    # Block 1 - Downsample using stride=2\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), strides=2, activation='relu', padding='same')(x) # Strides=2 for downsampling\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Block 2 - Downsample using stride=2\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), strides=2, activation='relu', padding='same', name='last_conv_nopool')(x) # Strides=2 and named for Grad-CAM\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Classification Head\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_No_Pooling\")\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_nopool = create_model_without_pooling()\n",
        "\n",
        "# Train Model 2\n",
        "history_nopool = model_nopool.fit(X_train, y_train, epochs=5, validation_split=0.1, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMJSNmc6-EDm",
        "outputId": "a8610fd7-8f05-4ad0-e806-3ca795c758a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 250ms/step - accuracy: 0.3488 - loss: 1.9600 - val_accuracy: 0.5292 - val_loss: 1.3956\n",
            "Epoch 2/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 230ms/step - accuracy: 0.5374 - loss: 1.2905 - val_accuracy: 0.6150 - val_loss: 1.0560\n",
            "Epoch 3/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 235ms/step - accuracy: 0.6300 - loss: 1.0543 - val_accuracy: 0.6556 - val_loss: 1.0054\n",
            "Epoch 4/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 227ms/step - accuracy: 0.6734 - loss: 0.9244 - val_accuracy: 0.7182 - val_loss: 0.8277\n",
            "Epoch 5/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 229ms/step - accuracy: 0.7101 - loss: 0.8286 - val_accuracy: 0.7264 - val_loss: 0.8112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model 1 (With Pooling)\n",
        "def create_model_with_pooling():\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Block 1 - Max Pooling\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Block 2 - Max Pooling\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name='last_conv_pool')(x) # Named for Grad-CAM\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Classification Head\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_With_Pooling\")\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_pool = create_model_with_pooling()\n",
        "\n",
        "# Train Model 1 (with Pooling)\n",
        "print(\"Training Model With Pooling...\")\n",
        "history_pool = model_pool.fit(X_train, y_train, epochs=5, validation_split=0.1, batch_size=64)\n",
        "\n",
        "# Evaluate Model 1\n",
        "loss_pool, acc_pool = model_pool.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Model With Pooling Test Accuracy: {acc_pool:.4f}\")\n",
        "\n",
        "# Evaluate Model 2\n",
        "loss_nopool, acc_nopool = model_nopool.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Model Without Pooling Test Accuracy: {acc_nopool:.4f}\")\n",
        "\n",
        "# Comparison Summary\n",
        "print(\"\\nAccuracy Comparison:\")\n",
        "print(f\"Model (Pooling): {acc_pool:.4f}\")\n",
        "print(f\"Model (No Pooling): {acc_nopool:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rpcYG6a-M5_",
        "outputId": "83015e97-3662-41fa-9dee-76680d4e81d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model With Pooling...\n",
            "Epoch 1/5\n",
            "\u001b[1m283/704\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 179ms/step - accuracy: 0.2886 - loss: 2.6125"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradcam(model, image, label_index, layer_name):\n",
        "    # grad_model needs to output the last conv layer and the final prediction layer\n",
        "    grad_model = Model(inputs=model.inputs,\n",
        "                       outputs=[model.get_layer(layer_name).output, model.output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Cast input image for gradient tape and add batch dimension\n",
        "        inputs = tf.cast(tf.expand_dims(image, axis=0), tf.float32)\n",
        "        conv_outputs, predictions = grad_model(inputs)\n",
        "        # Get the loss for the predicted label index (maximizes the score for the target class)\n",
        "        loss = predictions[:, label_index]\n",
        "\n",
        "    # Compute the gradients of the target class score w.r.t. the last conv layer's output\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    # Global average pooling of the gradients\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    # Multiply the activation map with the gradient importance (pooled_grads)\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Apply ReLU to get only features contributing positively to the class prediction\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def visualize_gradcam(model, X_test, y_test, image_index, layer_name, class_names):\n",
        "    image = X_test[image_index]\n",
        "    label = y_test[image_index][0] # CIFAR-10 labels are nested arrays\n",
        "\n",
        "    # Compute Grad-CAM\n",
        "    heatmap = compute_gradcam(model, image, label, layer_name)\n",
        "\n",
        "    # Resize heatmap to match input image (32x32)\n",
        "    heatmap_resized = tf.image.resize(heatmap[..., tf.newaxis], [32, 32]).numpy().squeeze()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(6, 3))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Org Image - Label: {class_names[label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Grad-CAM Overlay\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(heatmap_resized, cmap='jet', alpha=0.5)\n",
        "    plt.title(\"Grad-CAM Overlay\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# CIFAR-10 Class Names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Select a few images to visualize Grad-CAM on Model 1 (With Pooling)\n",
        "image_indices = [10, 20, 50, 60]\n",
        "layer_name_pool = 'last_conv_pool'\n",
        "\n",
        "for i in image_indices:\n",
        "    visualize_gradcam(model_pool, X_test, y_test, i, layer_name_pool, class_names)"
      ],
      "metadata": {
        "id": "Ex6ZLFIL-QSb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}